Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Ioannidis2005,
abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
archivePrefix = {arXiv},
arxivId = {gr-qc/0208024},
author = {Ioannidis, John P A},
doi = {10.1371/journal.pmed.0020124},
eprint = {0208024},
file = {:Users/lukas/Library/Application Support/Mendeley Desktop/Downloaded/Ioannidis - 2005 - Why most published research findings are false(2).pdf:pdf},
isbn = {3540239081},
issn = {15491277},
journal = {PLoS Medicine},
number = {8},
pages = {e124},
pmid = {16060722},
primaryClass = {gr-qc},
title = {{Why most published research findings are false}},
volume = {2},
year = {2005}
}
@article{Saelens2018a,
abstract = {A critical step in the analysis of large genome-wide gene expression datasets is the use of module detection methods to group genes into co-expression modules. Because of limitations of classical clustering methods, numerous alternative module detection methods have been proposed, which improve upon clustering by handling co-expression in only a subset of samples, modelling the regulatory network, and/or allowing overlap between modules. In this study we use known regulatory networks to do a comprehensive and robust evaluation of these different methods. Overall, decomposition methods outperform all other strategies, while we do not find a clear advantage of biclustering and network inference-based approaches on large gene expression datasets. Using our evaluation workflow, we also investigate several practical aspects of module detection, such as parameter estimation and the use of alternative similarity measures, and conclude with recommendations for the further development of these methods.},
author = {Saelens, Wouter and Cannoodt, Robrecht and Saeys, Yvan},
doi = {10.1038/s41467-018-03424-4},
file = {:Users/lukas/Dropbox/references/papers/Saelens2018 A comprehensive evaluation of module detection methods.pdf:pdf},
isbn = {2041-1723 (Electronic) 2041-1723 (Linking)},
issn = {20411723},
journal = {Nature Communications},
pages = {1090},
pmid = {29545622},
title = {{A comprehensive evaluation of module detection methods for gene expression data}},
volume = {9},
year = {2018}
}
@article{Zappia2018,
abstract = {As single-cell RNA-sequencing (scRNA-seq) datasets have become more widespread the number of tools designed to analyse these data has dramatically increased. Navigating the vast sea of tools now available is becoming increasingly challenging for researchers. In order to better facilitate selection of appropriate analysis tools we have created the scRNA-tools database (www.scRNA-tools.org) to catalogue and curate analysis tools as they become available. Our database collects a range of information on each scRNA-seq analysis tool and categorises them according to the analysis tasks they perform. Exploration of this database gives insights into the areas of rapid development of analysis methods for scRNA-seq data. We see that many tools perform tasks specific to scRNA-seq analysis, particularly clustering and ordering of cells. We also find that the scRNA-seq community embraces an open-source and open-science approach, with most tools available under open-source licenses and preprints being extensively used as a means to describe methods. The scRNA-tools database provides a valuable resource for researchers embarking on scRNA-seq analysis and records the growth of the field over time.},
author = {Zappia, Luke and Phipson, Belinda and Oshlack, Alicia},
doi = {10.1371/journal.pcbi.1006245},
file = {:Users/lukas/Dropbox/references/papers/Zappia2018 Exploring the single-cell RNA-seq analysis landscape.pdf:pdf},
isbn = {1111111111},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {6},
pages = {e1006245},
pmid = {29939984},
title = {{Exploring the single-cell RNA-seq analysis landscape with the scRNA-tools database}},
volume = {14},
year = {2018}
}
@article{Soneson2018,
author = {Soneson, Charlotte and Robinson, Mark D},
doi = {10.1038/nmeth.4612},
file = {:Users/lukas/Dropbox/references/papers/Soneson2018 Bias, robustness and scalability in single-cell differential.pdf:pdf},
issn = {1548-7091},
journal = {Nature Methods},
number = {4},
pages = {255--261},
pmid = {29481549},
publisher = {Nature Publishing Group},
title = {{Bias, robustness and scalability in single-cell differential expression analysis}},
url = {http://www.nature.com/doifinder/10.1038/nmeth.4612},
volume = {15},
year = {2018}
}
@article{Saelens2018b,
author = {Saelens, Wouter and Cannoodt, Robrecht and Todorov, Helena and Saeys, Yvan},
doi = {10.1101/276907},
file = {:Users/lukas/Dropbox/references/papers/Saelens2018 A comparison of single-cell trajectory inference methods.pdf:pdf},
journal = {bioRxiv preprint},
title = {{A comparison of single-cell trajectory inference methods: towards more accurate and robust tools}},
year = {2018}
}
@article{Weber2016,
abstract = {Recent technological developments in high-dimensional flow cytometry and mass cytometry (CyTOF) have made it possible to detect expression levels of dozens of protein markers in thousands of cells per second, allowing cell populations to be characterized in unprecedented detail. Traditional data analysis by "manual gating" can be inefficient and unreliable in these high-dimensional settings, which has led to the development of a large number of automated analysis methods. Methods designed for unsupervised analysis use specialized clustering algorithms to detect and define cell populations for further downstream analysis. Here, we have performed an up-to-date, extensible performance comparison of clustering methods for high-dimensional flow and mass cytometry data. We evaluated methods using several publicly available data sets from experiments in immunology, containing both major and rare cell populations, with cell population identities from expert manual gating as the reference standard. Several methods performed well, including FlowSOM, X-shift, PhenoGraph, Rclusterpp, and flowMeans. Among these, FlowSOM had extremely fast runtimes, making this method well-suited for interactive, exploratory analysis of large, high-dimensional data sets on a standard laptop or desktop computer. These results extend previously published comparisons by focusing on high-dimensional data and including new methods developed for CyTOF data. R scripts to reproduce all analyses are available from GitHub (https://github.com/lmweber/cytometry-clustering-comparison), and pre-processed data files are available from FlowRepository (FR-FCM-ZZPH), allowing our comparisons to be extended to include new clustering methods and reference data sets.},
author = {Weber, Lukas M and Robinson, Mark D},
doi = {10.1101/047613},
file = {:Users/lukas/Dropbox/references/papers/Weber2016{\_}Comparison{\_}of{\_}clustering{\_}methods.pdf:pdf},
issn = {15524922},
journal = {Cytometry Part A},
pages = {1084--1096},
pmid = {27992111},
title = {{Comparison of Clustering Methods for High-Dimensional Single-Cell Flow and Mass Cytometry Data}},
volume = {89A},
year = {2016}
}
@article{Peng2011,
abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
archivePrefix = {arXiv},
arxivId = {0901.4552},
author = {Peng, Roger D.},
doi = {10.1126/science.1213847},
eprint = {0901.4552},
file = {:Users/lukas/Dropbox/references/papers/Peng2011 Reproducible Research in Computational Science.pdf:pdf},
isbn = {1095-9203 (Electronic)$\backslash$r0036-8075 (Linking)},
issn = {10959203},
journal = {Science},
pages = {1226--1227},
pmid = {22144613},
title = {{Reproducible research in computational science}},
volume = {334},
year = {2011}
}
